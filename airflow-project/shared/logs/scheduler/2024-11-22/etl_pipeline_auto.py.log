[2024-11-22T09:18:42.691+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:18:42.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:18:42.697+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:18:42.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:18:42.718+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:18:42.716+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:18:42.719+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:18:42.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.062 seconds
[2024-11-22T09:19:12.984+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:12.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:19:12.987+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:12.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:12.993+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:12.992+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:19:12.994+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:13.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.029 seconds
[2024-11-22T09:19:26.130+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:26.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:19:26.134+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:26.164+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:26.447+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.446+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:data_pipeline_etl
[2024-11-22T09:19:26.454+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.453+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:data_pipeline_etl
[2024-11-22T09:19:26.456+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.456+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:data_pipeline_etl
[2024-11-22T09:19:26.459+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.459+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:data_pipeline_etl
[2024-11-22T09:19:26.462+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.462+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:data_pipeline_etl
[2024-11-22T09:19:26.465+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.465+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:data_pipeline_etl
[2024-11-22T09:19:26.468+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.468+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:data_pipeline_etl
[2024-11-22T09:19:26.468+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:19:26.707+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.706+0000] {dag.py:3262} INFO - Creating ORM DAG for data_pipeline_etl
[2024-11-22T09:19:26.740+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:26.740+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-21 23:00:00+00:00, run_after=2024-11-22 07:00:00+00:00
[2024-11-22T09:19:26.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.632 seconds
[2024-11-22T09:19:56.083+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:56.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:19:56.086+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:56.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:56.096+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:19:56.095+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:19:56.097+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:19:56.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.043 seconds
[2024-11-22T09:20:26.404+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:20:26.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:20:26.409+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:20:26.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:20:26.420+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:20:26.418+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:20:26.420+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:20:26.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.042 seconds
[2024-11-22T09:20:56.737+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:20:56.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:20:56.740+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:20:56.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:20:56.752+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:20:56.751+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:20:56.753+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:20:56.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.042 seconds
[2024-11-22T09:21:27.003+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:21:27.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:21:27.006+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:21:27.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:21:27.014+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:21:27.012+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:21:27.014+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:21:27.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.037 seconds
[2024-11-22T09:21:57.274+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:21:57.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:21:57.275+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:21:57.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:21:57.282+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:21:57.281+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:21:57.283+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:21:57.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.026 seconds
[2024-11-22T09:22:27.546+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:22:27.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:22:27.548+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:22:27.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:22:27.559+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:22:27.557+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:22:27.559+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:22:27.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.037 seconds
[2024-11-22T09:22:57.827+0000] {processor.py:186} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:22:57.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:22:57.831+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:22:57.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:22:57.845+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:22:57.843+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:22:57.846+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:22:57.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.047 seconds
[2024-11-22T09:23:28.084+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:23:28.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:23:28.086+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:23:28.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:23:28.095+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:23:28.093+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:23:28.095+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:23:28.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.031 seconds
[2024-11-22T09:23:58.403+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:23:58.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:23:58.405+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:23:58.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:23:58.414+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:23:58.412+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:23:58.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:23:58.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.036 seconds
[2024-11-22T09:24:28.687+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:24:28.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:24:28.689+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:24:28.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:24:28.698+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:24:28.697+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:24:28.699+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:24:28.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.033 seconds
[2024-11-22T09:24:58.982+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:24:58.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:24:58.984+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:24:58.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:24:58.992+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:24:58.990+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:24:58.993+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:24:59.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.031 seconds
[2024-11-22T09:25:29.272+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:25:29.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:25:29.274+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:25:29.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:25:29.281+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:25:29.280+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:25:29.281+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:25:29.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.030 seconds
[2024-11-22T09:25:59.581+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:25:59.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:25:59.583+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:25:59.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:25:59.590+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:25:59.589+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:25:59.591+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:25:59.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.027 seconds
[2024-11-22T09:26:29.917+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:26:29.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:26:29.919+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:26:29.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:26:29.935+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:26:29.933+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline_auto.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline_auto.py", line 34, in <module>
    upload_to_hdfs = BashOperator(
                     ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 484, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'
[2024-11-22T09:26:29.935+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:26:29.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.048 seconds
[2024-11-22T09:26:37.005+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:26:37.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:26:37.007+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:26:37.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:26:37.025+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:26:37.382+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:26:37.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:26:37.396+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:26:37.396+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:26:37.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.409 seconds
[2024-11-22T09:27:07.729+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:27:07.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:27:07.732+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:27:07.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:27:07.748+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:27:07.780+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:27:07.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:27:07.799+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:27:07.799+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:27:07.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.091 seconds
[2024-11-22T09:27:38.024+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:27:38.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:27:38.027+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:27:38.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:27:38.040+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:27:38.084+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:27:38.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:27:38.102+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:27:38.101+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:27:38.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.096 seconds
[2024-11-22T09:28:08.418+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:28:08.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:28:08.420+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:28:08.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:28:08.437+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:28:08.462+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:28:08.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:28:08.482+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:28:08.482+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:28:08.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.084 seconds
[2024-11-22T09:28:38.685+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:28:38.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:28:38.688+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:28:38.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:28:38.705+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:28:38.725+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:28:38.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:28:38.742+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:28:38.741+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:28:38.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.076 seconds
[2024-11-22T09:29:08.981+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:29:08.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:29:08.983+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:29:08.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:29:08.999+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:29:09.018+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:29:09.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:29:09.034+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:29:09.034+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:29:09.044+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.069 seconds
[2024-11-22T09:29:39.264+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:29:39.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:29:39.267+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:29:39.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:29:39.284+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:29:39.303+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:29:39.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:29:39.319+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:29:39.319+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:29:39.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.073 seconds
[2024-11-22T09:30:09.598+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:30:09.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:30:09.600+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:30:09.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:30:09.615+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:30:09.634+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:30:09.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:30:09.651+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:30:09.651+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:30:09.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.070 seconds
[2024-11-22T09:30:39.915+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:30:39.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:30:39.917+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:30:39.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:30:39.933+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:30:39.951+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:30:39.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:30:39.968+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:30:39.968+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:30:39.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.070 seconds
[2024-11-22T09:31:08.245+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:08.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:31:08.248+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:08.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:08.294+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:08.447+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:08.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:31:08.831+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:08.829+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:31:08.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.652 seconds
[2024-11-22T09:31:11.124+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:11.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:31:11.128+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:11.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:11.164+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:11.192+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:11.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:31:11.231+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:11.230+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:31:11.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.140 seconds
[2024-11-22T09:31:15.153+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:15.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:31:15.155+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:15.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:15.173+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:15.184+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:15.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:31:15.201+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:15.201+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:31:15.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.066 seconds
[2024-11-22T09:31:54.320+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:54.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:31:54.323+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:54.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:54.335+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:31:54.413+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:54.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:31:54.430+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:31:54.430+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:31:54.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.126 seconds
[2024-11-22T09:32:24.580+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:32:24.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:32:24.582+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:32:24.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:32:24.593+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:32:24.616+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:32:24.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:32:24.633+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:32:24.633+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:32:24.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.073 seconds
[2024-11-22T09:32:54.883+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:32:54.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:32:54.887+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:32:54.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:32:54.900+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:32:54.927+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:32:54.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:32:54.946+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:32:54.946+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:32:54.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.083 seconds
[2024-11-22T09:33:25.234+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:33:25.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:33:25.236+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:33:25.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:33:25.247+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:33:25.266+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:33:25.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:33:25.280+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:33:25.279+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:33:25.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.063 seconds
[2024-11-22T09:33:55.545+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:33:55.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:33:55.548+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:33:55.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:33:55.557+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:33:55.579+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:33:55.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:33:55.595+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:33:55.594+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:33:55.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.066 seconds
[2024-11-22T09:34:25.839+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:34:25.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:34:25.841+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:34:25.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:34:25.850+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:34:25.869+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:34:25.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:34:25.884+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:34:25.884+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:34:25.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.063 seconds
[2024-11-22T09:34:56.125+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:34:56.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:34:56.129+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:34:56.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:34:56.144+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:34:56.168+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:34:56.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:34:56.188+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:34:56.188+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to 2024-11-22 00:00:00+00:00, run_after=2024-11-22 00:00:00+00:00
[2024-11-22T09:34:56.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.082 seconds
[2024-11-22T09:35:26.358+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:35:26.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:35:26.362+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:35:26.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:35:26.376+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:35:26.402+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:35:26.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:35:26.421+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:35:26.421+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:35:26.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.084 seconds
[2024-11-22T09:35:57.466+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:35:57.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:35:57.471+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:35:57.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:35:57.487+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:35:57.516+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:35:57.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:35:57.787+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:35:57.787+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:35:57.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.339 seconds
[2024-11-22T09:36:28.140+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:36:28.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:36:28.146+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:36:28.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:36:28.170+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:36:28.208+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:36:28.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:36:28.514+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:36:28.514+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:36:28.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.404 seconds
[2024-11-22T09:36:58.852+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:36:58.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:36:58.856+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:36:58.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:36:58.865+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:36:59.030+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:36:59.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:36:59.048+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:36:59.048+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:36:59.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.216 seconds
[2024-11-22T09:37:29.118+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:37:29.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:37:29.122+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:37:29.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:37:29.358+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:37:29.375+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:37:29.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:37:29.389+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:37:29.389+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:37:29.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.289 seconds
[2024-11-22T09:37:59.679+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:37:59.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:37:59.682+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:37:59.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:37:59.691+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:37:59.710+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:37:59.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:37:59.728+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:37:59.727+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:37:59.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.066 seconds
[2024-11-22T09:38:30.017+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:38:30.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:38:30.023+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:38:30.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:38:30.040+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:38:30.080+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:38:30.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:38:30.108+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:38:30.108+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:38:30.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.115 seconds
[2024-11-22T09:39:00.327+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:39:00.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:39:00.331+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:39:00.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:39:00.343+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:39:00.369+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:39:00.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:39:00.389+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:39:00.388+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:39:00.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.084 seconds
[2024-11-22T09:39:30.624+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:39:30.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:39:30.629+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:39:30.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:39:30.640+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:39:30.663+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:39:30.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:39:30.678+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:39:30.678+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:39:30.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.070 seconds
[2024-11-22T09:40:01.028+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:40:01.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:40:01.033+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:40:01.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:40:01.049+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:40:01.076+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:40:01.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:40:01.096+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:40:01.096+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:40:01.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.090 seconds
[2024-11-22T09:40:31.371+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:40:31.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:40:31.375+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:40:31.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:40:31.386+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:40:31.409+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:40:31.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:40:31.426+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:40:31.426+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:40:31.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.077 seconds
[2024-11-22T09:41:01.718+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:41:01.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:41:01.723+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:41:01.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:41:01.739+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:41:01.771+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:41:01.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:41:01.797+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:41:01.797+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:41:01.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.108 seconds
[2024-11-22T09:41:32.065+0000] {processor.py:186} INFO - Started process (PID=69) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:41:32.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:41:32.069+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:41:32.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:41:32.082+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:41:32.102+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:41:32.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:41:32.121+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:41:32.120+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:41:32.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.078 seconds
[2024-11-22T09:42:02.402+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:42:02.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:42:02.406+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:42:02.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:42:02.418+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:42:02.442+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:42:02.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:42:02.461+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:42:02.461+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:42:02.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.083 seconds
[2024-11-22T09:42:32.734+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:42:32.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:42:32.738+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:42:32.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:42:32.747+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:42:32.768+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:42:32.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:42:32.782+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:42:32.781+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:42:32.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.066 seconds
[2024-11-22T09:43:03.109+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:43:03.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:43:03.113+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:43:03.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:43:03.123+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:43:03.144+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:43:03.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:43:03.162+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:43:03.162+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:43:03.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.074 seconds
[2024-11-22T09:43:33.492+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:43:33.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:43:33.497+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:43:33.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:43:33.511+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:43:33.538+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:43:33.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:43:33.562+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:43:33.562+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:43:33.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.091 seconds
[2024-11-22T09:44:03.831+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:44:03.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:44:03.836+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:44:03.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:44:03.846+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:44:03.870+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:44:03.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:44:03.888+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:44:03.887+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:44:03.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.076 seconds
[2024-11-22T09:44:34.195+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:44:34.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:44:34.199+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:44:34.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:44:34.208+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:44:34.227+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:44:34.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:44:34.243+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:44:34.243+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:44:34.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.066 seconds
[2024-11-22T09:45:04.533+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:45:04.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:45:04.536+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:45:04.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:45:04.546+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:45:04.567+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:45:04.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:45:04.585+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:45:04.585+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:45:04.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.070 seconds
[2024-11-22T09:45:34.855+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:45:34.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:45:34.860+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:45:34.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:45:34.871+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:45:34.893+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:45:34.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:45:34.910+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:45:34.910+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:45:34.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.076 seconds
[2024-11-22T09:46:05.188+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:46:05.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:46:05.191+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:46:05.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:46:05.200+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:46:05.220+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:46:05.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:46:05.236+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:46:05.236+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:46:05.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.068 seconds
[2024-11-22T09:46:35.551+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:46:35.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:46:35.554+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:46:35.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:46:35.564+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:46:35.584+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:46:35.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:46:35.598+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:46:35.598+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:46:35.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.065 seconds
[2024-11-22T09:47:05.925+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:47:05.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:47:05.930+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:47:05.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:47:05.942+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:47:05.965+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:47:05.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:47:05.984+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:47:05.984+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:47:05.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.079 seconds
[2024-11-22T09:47:36.269+0000] {processor.py:186} INFO - Started process (PID=81) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:47:36.270+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:47:36.273+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:47:36.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:47:36.282+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:47:36.304+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:47:36.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:47:36.322+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:47:36.322+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:47:36.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.075 seconds
[2024-11-22T09:48:06.592+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:48:06.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:48:06.596+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:48:06.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:48:06.607+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:48:06.624+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:48:06.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:48:06.638+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:48:06.638+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:48:06.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.064 seconds
[2024-11-22T09:48:36.994+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:48:36.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:48:36.997+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:48:36.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:48:37.005+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:48:37.025+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:48:37.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:48:37.042+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:48:37.042+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:48:37.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.068 seconds
[2024-11-22T09:49:07.348+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:49:07.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:49:07.351+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:49:07.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:49:07.364+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:49:07.388+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:49:07.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:49:07.406+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:49:07.406+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:49:07.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.080 seconds
[2024-11-22T09:49:37.710+0000] {processor.py:186} INFO - Started process (PID=85) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:49:37.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:49:37.715+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:49:37.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:49:37.729+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:49:37.751+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:49:37.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:49:37.768+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:49:37.768+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:49:37.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.078 seconds
[2024-11-22T09:50:08.061+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:50:08.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:50:08.065+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:50:08.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:50:08.079+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:50:08.105+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:50:08.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:50:08.127+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:50:08.127+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:50:08.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.086 seconds
[2024-11-22T09:50:38.442+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:50:38.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:50:38.448+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:50:38.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:50:38.465+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:50:38.497+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:50:38.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:50:38.522+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:50:38.521+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:50:38.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.108 seconds
[2024-11-22T09:51:08.846+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:51:08.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:51:08.850+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:51:08.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:51:08.861+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:51:08.885+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:51:08.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:51:08.902+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:51:08.902+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:51:08.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.074 seconds
[2024-11-22T09:51:39.153+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:51:39.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:51:39.165+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:51:39.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:51:39.188+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:51:39.220+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:51:39.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:51:39.243+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:51:39.243+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:51:39.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.121 seconds
[2024-11-22T09:52:09.616+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:52:09.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:52:09.621+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:52:09.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:52:09.638+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:52:09.669+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:52:09.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:52:09.693+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:52:09.693+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:52:09.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.104 seconds
[2024-11-22T09:52:39.939+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:52:39.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:52:39.942+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:52:39.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:52:39.950+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:52:39.970+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:52:39.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:52:39.985+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:52:39.985+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:52:39.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.065 seconds
[2024-11-22T09:53:10.258+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:53:10.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:53:10.260+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:53:10.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:53:10.270+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:53:10.290+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:53:10.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:53:10.308+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:53:10.308+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:53:10.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.070 seconds
[2024-11-22T09:53:40.607+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:53:40.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:53:40.613+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:53:40.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:53:40.633+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:53:40.668+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:53:40.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:53:40.692+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:53:40.692+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:53:40.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.111 seconds
[2024-11-22T09:54:10.928+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:54:10.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:54:10.931+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:54:10.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:54:10.941+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:54:10.978+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:54:10.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:54:10.996+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:54:10.996+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:54:11.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.090 seconds
[2024-11-22T09:54:41.372+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:54:41.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:54:41.379+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:54:41.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:54:41.403+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:54:41.460+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:54:41.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:54:41.485+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:54:41.485+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:54:41.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.138 seconds
[2024-11-22T09:55:11.651+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:55:11.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:55:11.656+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:55:11.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:55:11.669+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:55:11.697+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:55:11.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:55:11.712+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:55:11.712+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:55:11.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.081 seconds
[2024-11-22T09:55:41.939+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:55:41.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:55:41.946+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:55:41.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:55:41.958+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:55:41.985+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:55:41.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:55:42.003+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:55:42.003+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:55:42.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.088 seconds
[2024-11-22T09:56:12.298+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:56:12.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:56:12.307+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:56:12.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:56:12.329+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:56:12.399+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:56:12.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:56:12.429+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:56:12.429+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:56:12.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.160 seconds
[2024-11-22T09:56:42.679+0000] {processor.py:186} INFO - Started process (PID=99) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:56:42.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:56:42.683+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:56:42.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:56:42.696+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:56:42.730+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:56:42.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:56:42.748+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:56:42.748+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:56:42.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.094 seconds
[2024-11-22T09:57:13.098+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:57:13.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:57:13.103+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:57:13.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:57:13.118+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:57:13.160+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:57:13.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:57:13.181+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:57:13.181+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:57:13.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.106 seconds
[2024-11-22T09:57:43.476+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:57:43.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:57:43.480+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:57:43.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:57:43.494+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:57:43.534+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:57:43.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:57:43.556+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:57:43.555+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:57:43.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.108 seconds
[2024-11-22T09:58:13.923+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:58:13.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:58:13.929+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:58:13.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:58:13.947+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:58:13.990+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:58:13.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:58:14.011+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:58:14.011+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:58:14.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.113 seconds
[2024-11-22T09:58:44.301+0000] {processor.py:186} INFO - Started process (PID=103) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:58:44.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:58:44.303+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:58:44.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:58:44.312+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:58:44.333+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:58:44.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:58:44.350+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:58:44.350+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:58:44.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.067 seconds
[2024-11-22T09:59:14.631+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:59:14.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:59:14.639+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:59:14.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:59:14.657+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:59:14.705+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:59:14.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:59:14.731+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:59:14.731+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:59:14.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.128 seconds
[2024-11-22T09:59:45.025+0000] {processor.py:186} INFO - Started process (PID=105) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:59:45.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T09:59:45.037+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:59:45.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:59:45.060+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T09:59:45.116+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:59:45.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T09:59:45.141+0000] {logging_mixin.py:190} INFO - [2024-11-22T09:59:45.140+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T09:59:45.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.145 seconds
[2024-11-22T10:00:15.448+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:00:15.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:00:15.456+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:00:15.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:00:15.480+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:00:15.544+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:00:15.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:00:15.571+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:00:15.571+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:00:15.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.148 seconds
[2024-11-22T10:00:45.766+0000] {processor.py:186} INFO - Started process (PID=107) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:00:45.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:00:45.770+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:00:45.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:00:45.779+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:00:45.804+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:00:45.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:00:45.820+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:00:45.820+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:00:45.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.075 seconds
[2024-11-22T10:01:16.076+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:01:16.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:01:16.079+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:01:16.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:01:16.088+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:01:16.113+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:01:16.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:01:16.128+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:01:16.128+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:01:16.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.077 seconds
[2024-11-22T10:01:46.459+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:01:46.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:01:46.463+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:01:46.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:01:46.472+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:01:46.496+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:01:46.496+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:01:46.514+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:01:46.514+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:01:46.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.075 seconds
[2024-11-22T10:02:16.833+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:02:16.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:02:16.837+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:02:16.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:02:16.846+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:02:16.873+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:02:16.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:02:16.893+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:02:16.892+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:02:16.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.080 seconds
[2024-11-22T10:02:47.165+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:02:47.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:02:47.168+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:02:47.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:02:47.178+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:02:47.204+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:02:47.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:02:47.222+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:02:47.222+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:02:47.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.077 seconds
[2024-11-22T10:03:17.501+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:03:17.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:03:17.505+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:03:17.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:03:17.514+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:03:17.538+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:03:17.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:03:17.554+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:03:17.554+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:03:17.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.070 seconds
[2024-11-22T10:03:47.830+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:03:47.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:03:47.835+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:03:47.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:03:47.851+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:03:47.891+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:03:47.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:03:47.911+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:03:47.910+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:03:47.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.105 seconds
[2024-11-22T10:04:18.219+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:04:18.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:04:18.224+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:04:18.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:04:18.234+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:04:18.263+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:04:18.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:04:18.281+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:04:18.281+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:04:18.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.082 seconds
[2024-11-22T10:04:48.544+0000] {processor.py:186} INFO - Started process (PID=115) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:04:48.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:04:48.548+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:04:48.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:04:48.558+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:04:48.585+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:04:48.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:04:48.601+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:04:48.601+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:04:48.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.076 seconds
[2024-11-22T10:05:18.971+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:05:18.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:05:18.974+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:05:18.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:05:18.983+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:05:19.005+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:05:19.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:05:19.022+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:05:19.022+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:05:19.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.069 seconds
[2024-11-22T10:05:49.310+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:05:49.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:05:49.314+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:05:49.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:05:49.328+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:05:49.347+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:05:49.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:05:49.363+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:05:49.363+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:05:49.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.076 seconds
[2024-11-22T10:06:19.657+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:06:19.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:06:19.661+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:06:19.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:06:19.677+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:06:19.697+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:06:19.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:06:19.714+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:06:19.714+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:06:19.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.077 seconds
[2024-11-22T10:06:50.011+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:06:50.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:06:50.038+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:06:50.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:06:50.063+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:06:50.087+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:06:50.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:06:50.108+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:06:50.107+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:06:50.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.124 seconds
[2024-11-22T10:07:20.393+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:07:20.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:07:20.397+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:07:20.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:07:20.418+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:07:20.441+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:07:20.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:07:20.462+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:07:20.462+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:07:20.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.090 seconds
[2024-11-22T10:07:50.742+0000] {processor.py:186} INFO - Started process (PID=121) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:07:50.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:07:50.748+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:07:50.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:07:50.763+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:07:50.784+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:07:50.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:07:50.801+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:07:50.801+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:07:50.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.085 seconds
[2024-11-22T10:08:21.087+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:08:21.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:08:21.091+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:08:21.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:08:21.108+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:08:21.129+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:08:21.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:08:21.146+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:08:21.146+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:08:21.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.078 seconds
[2024-11-22T10:08:51.440+0000] {processor.py:186} INFO - Started process (PID=123) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:08:51.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:08:51.443+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:08:51.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:08:51.460+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:08:51.481+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:08:51.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:08:51.495+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:08:51.495+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:08:51.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.074 seconds
[2024-11-22T10:09:21.775+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:09:21.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_auto.py for tasks to queue
[2024-11-22T10:09:21.778+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:09:21.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:09:21.795+0000] {processor.py:925} INFO - DAG(s) 'data_pipeline_etl' retrieved from /opt/airflow/dags/etl_pipeline_auto.py
[2024-11-22T10:09:21.814+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:09:21.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-22T10:09:21.829+0000] {logging_mixin.py:190} INFO - [2024-11-22T10:09:21.829+0000] {dag.py:4180} INFO - Setting next_dagrun for data_pipeline_etl to None, run_after=None
[2024-11-22T10:09:21.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_auto.py took 0.075 seconds
